#!/usr/bin/env python3
"""
é€šç”¨æ•°æ®åº“è¿ç§»è„šæœ¬
- æ¯æ¬¡æ•°æ®åº“ä¿®æ”¹æ—¶ï¼Œæ›´æ–°æ­¤æ–‡ä»¶å†…å®¹
- æ‰§è¡Œå®Œæˆåè‡ªåŠ¨æ ‡è®°ä¸ºå·²å®Œæˆ
- ä¸‹æ¬¡éƒ¨ç½²æ—¶å¦‚æ— æ–°è¿ç§»åˆ™è·³è¿‡
"""

import sqlite3
import sys
import os
import logging
from datetime import datetime

# ä¿®å¤æ¨¡å—è·¯å¾„é—®é¢˜
sys.path.insert(0, os.path.dirname(__file__))

# å¯¼å…¥è¿ç§»å·¥å…·
from migration_utils import setup_migration_logging, find_database_path, backup_database, get_table_columns, table_exists

logger = setup_migration_logging()

# è¿ç§»ç‰ˆæœ¬å· - å½»åº•ä¿®å¤datetimeå­—æ®µæ˜ å°„é”™è¯¯ï¼ˆç´§æ€¥ä¿®å¤APIè¿”å›ç©ºæ•°ç»„é—®é¢˜ï¼‰
MIGRATION_VERSION = "v1.23_critical_datetime_fix"

def check_if_migration_completed(db_path):
    """æ£€æŸ¥è¿ç§»æ˜¯å¦å·²å®Œæˆ"""
    try:
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        # åˆ›å»ºè¿ç§»è®°å½•è¡¨ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS migration_history (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                version TEXT UNIQUE,
                executed_at DATETIME DEFAULT CURRENT_TIMESTAMP
            )
        """)
        
        # æ£€æŸ¥å½“å‰ç‰ˆæœ¬æ˜¯å¦å·²æ‰§è¡Œ
        cursor.execute("SELECT version FROM migration_history WHERE version = ?", (MIGRATION_VERSION,))
        result = cursor.fetchone()
        
        conn.close()
        return result is not None
    except Exception as e:
        logger.error(f"æ£€æŸ¥è¿ç§»çŠ¶æ€å¤±è´¥: {e}")
        return False

def mark_migration_completed(db_path):
    """æ ‡è®°è¿ç§»ä¸ºå·²å®Œæˆ"""
    try:
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        cursor.execute("INSERT OR IGNORE INTO migration_history (version) VALUES (?)", (MIGRATION_VERSION,))
        conn.commit()
        conn.close()
        logger.info(f"è¿ç§»ç‰ˆæœ¬ {MIGRATION_VERSION} å·²æ ‡è®°ä¸ºå®Œæˆ")
    except Exception as e:
        logger.error(f"æ ‡è®°è¿ç§»å®Œæˆå¤±è´¥: {e}")

def run_migration():
    """æ‰§è¡Œå½“å‰è¿ç§»ä»»åŠ¡"""
    # ä½¿ç”¨å·¥å…·å‡½æ•°æŸ¥æ‰¾æ•°æ®åº“è·¯å¾„
    db_path = find_database_path()
    if not db_path:
        logger.error("æ‰¾ä¸åˆ°æ•°æ®åº“æ–‡ä»¶")
        return False
    
    logger.info(f"ä½¿ç”¨æ•°æ®åº“æ–‡ä»¶: {db_path}")
    
    # æ£€æŸ¥æ˜¯å¦å·²æ‰§è¡Œè¿‡
    if check_if_migration_completed(db_path):
        logger.info(f"è¿ç§» {MIGRATION_VERSION} å·²æ‰§è¡Œè¿‡ï¼Œè·³è¿‡")
        return True
    
    # å¤‡ä»½æ•°æ®åº“
    backup_path = backup_database(db_path)
    
    try:
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        logger.info(f"å¼€å§‹æ‰§è¡Œè¿ç§»: {MIGRATION_VERSION}")
        
        # ===========================================
        # ğŸš¨ v1.23è¿ç§»ä»»åŠ¡ï¼šå½»åº•ä¿®å¤datetimeå­—æ®µæ˜ å°„é”™è¯¯
        # ç´§æ€¥ä¿®å¤APIè¿”å›ç©ºæ•°ç»„é—®é¢˜ - 2025-07-24
        # ===========================================
        
        logger.info("ğŸš¨ å¼€å§‹v1.23è¿ç§»ï¼šå½»åº•ä¿®å¤datetimeå­—æ®µæ˜ å°„é”™è¯¯...")
        logger.info("ğŸ¯ ç›®æ ‡ï¼šä¿®å¤Pydantic 'Invalid isoformat string' é”™è¯¯ï¼Œæ¢å¤APIæ­£å¸¸å·¥ä½œ")
        
        # ç¬¬ä¸€æ­¥ï¼šå…¨é¢è¯Šæ–­æ‰€æœ‰è¡¨çš„datetimeå­—æ®µé”™è¯¯
        logger.info("ğŸ” å…¨é¢è¯Šæ–­æ‰€æœ‰è¡¨çš„datetimeå­—æ®µé—®é¢˜...")
        
        # å®šä¹‰éœ€è¦æ£€æŸ¥çš„è¡¨å’Œå­—æ®µ
        tables_to_check = [
            ('collaborators', ['created_at', 'updated_at', 'deleted_at']),
            ('research_projects', ['created_at', 'updated_at', 'deleted_at']),
            ('ideas', ['created_at', 'updated_at', 'deleted_at']),
            ('communication_logs', ['created_at', 'updated_at', 'deleted_at']),
            ('project_collaborators', ['created_at', 'updated_at'])
        ]
        
        total_errors_found = 0
        
        for table_name, datetime_fields in tables_to_check:
            if table_exists(cursor, table_name):
                logger.info(f"æ£€æŸ¥è¡¨: {table_name}")
                
                # æ£€æŸ¥è¡¨ç»“æ„
                cursor.execute(f"PRAGMA table_info({table_name})")
                columns_info = cursor.fetchall()
                existing_fields = {col[1] for col in columns_info}
                
                for field in datetime_fields:
                    if field in existing_fields:
                        # æ£€æŸ¥æ— æ•ˆçš„datetimeå€¼
                        cursor.execute(f"""
                            SELECT COUNT(*) FROM {table_name} 
                            WHERE {field} IS NOT NULL 
                            AND (
                                {field} = 'senior' OR 
                                {field} = 'junior' OR 
                                {field} = '' OR
                                {field} NOT LIKE '____-__-__%'
                            )
                        """)
                        error_count = cursor.fetchone()[0]
                        
                        if error_count > 0:
                            logger.warning(f"  âŒ {table_name}.{field}: {error_count} ä¸ªé”™è¯¯å€¼")
                            total_errors_found += error_count
                        else:
                            logger.info(f"  âœ… {table_name}.{field}: æ ¼å¼æ­£ç¡®")
                    else:
                        logger.info(f"  â­ï¸ {table_name}.{field}: å­—æ®µä¸å­˜åœ¨")
            else:
                logger.info(f"â­ï¸ è¡¨ {table_name} ä¸å­˜åœ¨")
        
        logger.info(f"ğŸ” è¯Šæ–­å®Œæˆï¼Œå…±å‘ç° {total_errors_found} ä¸ªdatetimeæ ¼å¼é”™è¯¯")
        
        # ç¬¬äºŒæ­¥ï¼šæ‰§è¡Œå½»åº•çš„datetimeå­—æ®µä¿®å¤
        if total_errors_found > 0:
            logger.info("ğŸ”§ å¼€å§‹æ‰§è¡Œå½»åº•çš„datetimeå­—æ®µä¿®å¤...")
            
            total_fixed = 0
            
            for table_name, datetime_fields in tables_to_check:
                if table_exists(cursor, table_name):
                    # è·å–è¡¨ç»“æ„
                    cursor.execute(f"PRAGMA table_info({table_name})")
                    columns_info = cursor.fetchall()
                    existing_fields = {col[1] for col in columns_info}
                    
                    for field in datetime_fields:
                        if field in existing_fields:
                            # ä¿®å¤æ‰€æœ‰æ— æ•ˆçš„datetimeå€¼
                            if field == 'deleted_at':
                                # deleted_atå­—æ®µè®¾ä¸ºNULL
                                cursor.execute(f"""
                                    UPDATE {table_name} 
                                    SET {field} = NULL 
                                    WHERE {field} IS NOT NULL 
                                    AND (
                                        {field} = 'senior' OR 
                                        {field} = 'junior' OR 
                                        {field} = '' OR
                                        {field} NOT LIKE '____-__-__%'
                                    )
                                """)
                            else:
                                # created_atå’Œupdated_atè®¾ä¸ºå½“å‰æ—¶é—´
                                cursor.execute(f"""
                                    UPDATE {table_name} 
                                    SET {field} = datetime('now') 
                                    WHERE {field} IS NOT NULL 
                                    AND (
                                        {field} = 'senior' OR 
                                        {field} = 'junior' OR 
                                        {field} = '' OR
                                        {field} NOT LIKE '____-__-__%'
                                    )
                                """)
                            
                            fixed_count = cursor.rowcount
                            if fixed_count > 0:
                                logger.info(f"  âœ… ä¿®å¤ {table_name}.{field}: {fixed_count} æ¡è®°å½•")
                                total_fixed += fixed_count
            
            logger.info(f"ğŸ‰ datetimeå­—æ®µä¿®å¤å®Œæˆï¼Œå…±ä¿®å¤ {total_fixed} ä¸ªé”™è¯¯å€¼")
        else:
            logger.info("âœ… æœªå‘ç°datetimeæ ¼å¼é”™è¯¯ï¼Œè·³è¿‡ä¿®å¤")
        
        # ç¬¬ä¸‰æ­¥ï¼šæ•°æ®å®Œæ•´æ€§éªŒè¯
        logger.info("ğŸ” æ‰§è¡Œæ•°æ®å®Œæ•´æ€§éªŒè¯...")
        
        # éªŒè¯æ‰€æœ‰è¡¨çš„è®°å½•æ•°
        for table_name, _ in tables_to_check:
            if table_exists(cursor, table_name):
                cursor.execute(f"SELECT COUNT(*) FROM {table_name}")
                count = cursor.fetchone()[0]
                logger.info(f"  ğŸ“Š {table_name}: {count} æ¡è®°å½•")
                
                # ç‰¹åˆ«æ£€æŸ¥collaboratorsè¡¨çš„levelå­—æ®µåˆ†å¸ƒ
                if table_name == 'collaborators':
                    cursor.execute("PRAGMA table_info(collaborators)")
                    columns_info = cursor.fetchall()
                    has_level = any(col[1] == 'level' for col in columns_info)
                    
                    if has_level:
                        cursor.execute("SELECT level, COUNT(*) FROM collaborators GROUP BY level")
                        level_dist = cursor.fetchall()
                        logger.info(f"    ğŸ“ˆ levelåˆ†å¸ƒ: {level_dist}")
                    
                    # æ£€æŸ¥æ´»è·ƒcollaborators
                    cursor.execute("SELECT COUNT(*) FROM collaborators WHERE deleted_at IS NULL")
                    active = cursor.fetchone()[0]
                    logger.info(f"    ğŸ‘¥ æ´»è·ƒcollaborators: {active} ä¸ª")
        
        # ç¬¬å››æ­¥ï¼šæœ€ç»ˆéªŒè¯ - ç¡®ä¿æ²¡æœ‰æ®‹ç•™çš„é”™è¯¯æ ¼å¼
        logger.info("ğŸ” æœ€ç»ˆéªŒè¯ - æ£€æŸ¥æ®‹ç•™çš„æ ¼å¼é”™è¯¯...")
        
        remaining_errors = 0
        for table_name, datetime_fields in tables_to_check:
            if table_exists(cursor, table_name):
                cursor.execute(f"PRAGMA table_info({table_name})")
                columns_info = cursor.fetchall()
                existing_fields = {col[1] for col in columns_info}
                
                for field in datetime_fields:
                    if field in existing_fields:
                        cursor.execute(f"""
                            SELECT COUNT(*) FROM {table_name} 
                            WHERE {field} IS NOT NULL 
                            AND (
                                {field} = 'senior' OR 
                                {field} = 'junior' OR 
                                {field} = '' OR
                                {field} NOT LIKE '____-__-__%'
                            )
                        """)
                        error_count = cursor.fetchone()[0]
                        remaining_errors += error_count
                        
                        if error_count > 0:
                            logger.error(f"  âŒ {table_name}.{field}: ä»æœ‰ {error_count} ä¸ªæ ¼å¼é”™è¯¯")
        
        if remaining_errors == 0:
            logger.info("âœ… æœ€ç»ˆéªŒè¯é€šè¿‡ï¼Œæ‰€æœ‰datetimeå­—æ®µæ ¼å¼æ­£ç¡®")
        else:
            logger.warning(f"âš ï¸ æœ€ç»ˆéªŒè¯å‘ç° {remaining_errors} ä¸ªæ®‹ç•™é”™è¯¯")
        
        # ç¬¬äº”æ­¥ï¼šæäº¤æ›´æ”¹å¹¶æ ‡è®°å®Œæˆ
        conn.commit()
        mark_migration_completed(db_path)
        
        logger.info(f"è¿ç§» {MIGRATION_VERSION} æ‰§è¡ŒæˆåŠŸ")
        
        logger.info("=" * 70)
        logger.info("ğŸ‰ v1.23 å½»åº•ä¿®å¤datetimeå­—æ®µæ˜ å°„é”™è¯¯å®Œæˆï¼")
        logger.info("âœ… ä¿®å¤äº†æ‰€æœ‰è¡¨ä¸­çš„'senior'/'junior'å­—ç¬¦ä¸²é”™è¯¯")
        logger.info("âœ… ç»Ÿä¸€äº†æ‰€æœ‰datetimeå­—æ®µçš„æ ¼å¼")
        logger.info("âœ… æ¸…ç†äº†æ‰€æœ‰deleted_atå­—æ®µçš„é”™è¯¯å€¼")
        logger.info("âœ… éªŒè¯äº†æ•°æ®å®Œæ•´æ€§")
        logger.info(f"âœ… å…±ä¿®å¤äº† {total_errors_found} ä¸ªdatetimeæ ¼å¼é”™è¯¯")
        logger.info(f"âœ… å‰©ä½™æ ¼å¼é”™è¯¯: {remaining_errors} ä¸ª")
        logger.info("ğŸ“ Pydantic 'Invalid isoformat string' é”™è¯¯åº”è¯¥å½»åº•è§£å†³")
        logger.info("ğŸš€ æ‰€æœ‰APIåº”è¯¥ç«‹å³æ¢å¤æ­£å¸¸å·¥ä½œï¼Œä¸å†è¿”å›ç©ºæ•°ç»„")
        logger.info("ğŸ”§ è§£å†³äº†å¯¼è‡´APIå“åº”ä¸ºç©ºçš„æ ¹æœ¬åŸå› ")
        logger.info("=" * 70)
        
        conn.close()
        
        return True
        
    except Exception as e:
        logger.error(f"è¿ç§»æ‰§è¡Œå¤±è´¥: {e}")
        logger.error(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
        logger.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {str(e)}")
        
        # å°è¯•å›æ»šäº‹åŠ¡
        try:
            conn.rollback()
            logger.info("äº‹åŠ¡å·²å›æ»š")
        except:
            logger.error("æ— æ³•å›æ»šäº‹åŠ¡")
        
        # å…³é—­è¿æ¥
        try:
            conn.close()
        except:
            pass
            
        logger.info(f"æ•°æ®åº“å¤‡ä»½ä½äº: {backup_path}")
        logger.error("å»ºè®®ä»å¤‡ä»½æ¢å¤æ•°æ®åº“")
        return False

if __name__ == "__main__":
    logger.info(f"å¼€å§‹æ‰§è¡Œè¿ç§»ç‰ˆæœ¬: {MIGRATION_VERSION}")
    logger.info(f"æ‰§è¡Œæ—¶é—´: {datetime.now()}")
    
    try:
        success = run_migration()
        
        if success:
            logger.info("âœ… è¿ç§»æ‰§è¡ŒæˆåŠŸ")
            print("Migration completed successfully")
            sys.exit(0)
        else:
            logger.error("âŒ è¿ç§»æ‰§è¡Œå¤±è´¥")
            print("Migration failed")
            sys.exit(1)
            
    except KeyboardInterrupt:
        logger.warning("è¿ç§»è¢«ç”¨æˆ·ä¸­æ–­")
        print("Migration interrupted by user")
        sys.exit(1)
        
    except Exception as e:
        logger.error(f"æœªé¢„æœŸçš„é”™è¯¯: {e}")
        print(f"Unexpected error: {e}")
        sys.exit(1)