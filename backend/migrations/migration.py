#!/usr/bin/env python3
"""
é€šç”¨æ•°æ®åº“è¿ç§»è„šæœ¬
- æ¯æ¬¡æ•°æ®åº“ä¿®æ”¹æ—¶ï¼Œæ›´æ–°æ­¤æ–‡ä»¶å†…å®¹
- æ‰§è¡Œå®Œæˆåè‡ªåŠ¨æ ‡è®°ä¸ºå·²å®Œæˆ
- ä¸‹æ¬¡éƒ¨ç½²æ—¶å¦‚æ— æ–°è¿ç§»åˆ™è·³è¿‡
"""

import sqlite3
import sys
import os
import logging
import re
from datetime import datetime

# ä¿®å¤æ¨¡å—è·¯å¾„é—®é¢˜
sys.path.insert(0, os.path.dirname(__file__))

# å¯¼å…¥è¿ç§»å·¥å…·
from migration_utils import setup_migration_logging, find_database_path, backup_database, get_table_columns, table_exists

logger = setup_migration_logging()

# è¿ç§»ç‰ˆæœ¬å· - æœŸåˆŠTagsç³»ç»Ÿ
MIGRATION_VERSION = "v3.0_journal_tags_system"

def check_if_migration_completed(db_path):
    """æ£€æŸ¥è¿ç§»æ˜¯å¦å·²å®Œæˆ"""
    try:
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()

        # åˆ›å»ºè¿ç§»è®°å½•è¡¨ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS migration_history (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                version TEXT UNIQUE,
                executed_at DATETIME DEFAULT CURRENT_TIMESTAMP
            )
        """)

        # æ£€æŸ¥å½“å‰ç‰ˆæœ¬æ˜¯å¦å·²æ‰§è¡Œ
        cursor.execute("SELECT version FROM migration_history WHERE version = ?", (MIGRATION_VERSION,))
        result = cursor.fetchone()

        conn.close()
        return result is not None
    except Exception as e:
        logger.error(f"æ£€æŸ¥è¿ç§»çŠ¶æ€å¤±è´¥: {e}")
        return False

def mark_migration_completed(db_path):
    """æ ‡è®°è¿ç§»ä¸ºå·²å®Œæˆ"""
    try:
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        cursor.execute("INSERT OR IGNORE INTO migration_history (version) VALUES (?)", (MIGRATION_VERSION,))
        conn.commit()
        conn.close()
        logger.info(f"è¿ç§»ç‰ˆæœ¬ {MIGRATION_VERSION} å·²æ ‡è®°ä¸ºå®Œæˆ")
    except Exception as e:
        logger.error(f"æ ‡è®°è¿ç§»å®Œæˆå¤±è´¥: {e}")

def run_migration():
    """æ‰§è¡Œå½“å‰è¿ç§»ä»»åŠ¡"""
    # ä½¿ç”¨å·¥å…·å‡½æ•°æŸ¥æ‰¾æ•°æ®åº“è·¯å¾„
    db_path = find_database_path()
    if not db_path:
        logger.error("æ‰¾ä¸åˆ°æ•°æ®åº“æ–‡ä»¶")
        return False

    logger.info(f"ä½¿ç”¨æ•°æ®åº“æ–‡ä»¶: {db_path}")

    # æ£€æŸ¥æ˜¯å¦å·²æ‰§è¡Œè¿‡
    if check_if_migration_completed(db_path):
        logger.info(f"è¿ç§» {MIGRATION_VERSION} å·²æ‰§è¡Œè¿‡ï¼Œè·³è¿‡")
        return True

    # å¤‡ä»½æ•°æ®åº“
    backup_path = backup_database(db_path)

    try:
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()

        logger.info("=" * 70)
        logger.info(f"ğŸš€ å¼€å§‹æ‰§è¡Œè¿ç§»: {MIGRATION_VERSION}")
        logger.info("ğŸ¯ ç›®æ ‡: åˆ›å»ºTagsè¡¨å’Œjournal_tagså…³è”è¡¨ï¼Œåˆ é™¤categoryå’Œimpact_factorå­—æ®µ")
        logger.info("=" * 70)

        # ===========================================
        # ğŸ”§ v3.0è¿ç§»ä»»åŠ¡ï¼šæœŸåˆŠTagsç³»ç»Ÿ
        # å˜æ›´ï¼š
        # 1. åˆ›å»ºtagsè¡¨ï¼ˆæ ‡ç­¾å®šä¹‰ï¼‰
        # 2. åˆ›å»ºjournal_tagsè¡¨ï¼ˆå¤šå¯¹å¤šå…³è”ï¼‰
        # 3. æå–ç°æœ‰categoryåˆ›å»ºæ ‡ç­¾
        # 4. å»ºç«‹æœŸåˆŠ-æ ‡ç­¾å…³è”
        # 5. é‡å»ºjournalsè¡¨ï¼ˆåˆ é™¤categoryå’Œimpact_factorå­—æ®µï¼‰
        # ===========================================

        # ============================
        # Step 1: åˆ›å»ºtagsè¡¨å’Œjournal_tagsè¡¨
        # ============================
        logger.info("\nğŸ“‹ Step 1: åˆ›å»ºtagsè¡¨å’Œjournal_tagsè¡¨")

        if not table_exists(cursor, 'tags'):
            cursor.execute("""
                CREATE TABLE tags (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    name TEXT NOT NULL UNIQUE,
                    description TEXT,
                    color TEXT DEFAULT 'blue',
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                    updated_at DATETIME DEFAULT CURRENT_TIMESTAMP
                )
            """)
            logger.info("   âœ… åˆ›å»ºè¡¨: tags")

            # åˆ›å»ºç´¢å¼•
            cursor.execute("CREATE INDEX idx_tag_name ON tags(name)")
            logger.info("   âœ… åˆ›å»ºç´¢å¼•: idx_tag_name")
        else:
            logger.info("   â­ï¸  è¡¨å·²å­˜åœ¨: tags")

        if not table_exists(cursor, 'journal_tags'):
            cursor.execute("""
                CREATE TABLE journal_tags (
                    journal_id INTEGER NOT NULL,
                    tag_id INTEGER NOT NULL,
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                    PRIMARY KEY (journal_id, tag_id),
                    FOREIGN KEY (journal_id) REFERENCES journals(id) ON DELETE CASCADE,
                    FOREIGN KEY (tag_id) REFERENCES tags(id) ON DELETE CASCADE
                )
            """)
            logger.info("   âœ… åˆ›å»ºè¡¨: journal_tags")

            # åˆ›å»ºç´¢å¼•
            cursor.execute("CREATE INDEX idx_journal_tags_journal ON journal_tags(journal_id)")
            cursor.execute("CREATE INDEX idx_journal_tags_tag ON journal_tags(tag_id)")
            logger.info("   âœ… åˆ›å»ºç´¢å¼•: journal_tagsç´¢å¼•")
        else:
            logger.info("   â­ï¸  è¡¨å·²å­˜åœ¨: journal_tags")

        # ============================
        # Step 2: æå–ç°æœ‰categoryåˆ›å»ºæ ‡ç­¾
        # ============================
        logger.info("\nğŸ“‹ Step 2: æå–ç°æœ‰categoryåˆ›å»ºæ ‡ç­¾")

        # æå–æ‰€æœ‰éç©ºåˆ†ç±»
        cursor.execute("""
            SELECT DISTINCT category
            FROM journals
            WHERE category IS NOT NULL AND category != ''
            ORDER BY category
        """)
        categories = cursor.fetchall()
        logger.info(f"   ğŸ“Š å‘ç° {len(categories)} ä¸ªä¸åŒçš„åˆ†ç±»")

        # åˆ›å»ºæ ‡ç­¾å¹¶å»ºç«‹æ˜ å°„
        tag_mapping = {}
        for category_name, in categories:
            # æ£€æŸ¥æ ‡ç­¾æ˜¯å¦å·²å­˜åœ¨
            cursor.execute("SELECT id FROM tags WHERE name = ?", (category_name,))
            existing_tag = cursor.fetchone()

            if existing_tag:
                tag_id = existing_tag[0]
                logger.info(f"   â­ï¸  æ ‡ç­¾å·²å­˜åœ¨: {category_name} (ID: {tag_id})")
            else:
                cursor.execute("""
                    INSERT INTO tags (name, description, color)
                    VALUES (?, ?, ?)
                """, (category_name, f'ä»æ—§åˆ†ç±»"{category_name}"è‡ªåŠ¨è¿ç§»', 'blue'))

                tag_id = cursor.lastrowid
                logger.info(f"   âœ… åˆ›å»ºæ ‡ç­¾: {category_name} (ID: {tag_id})")

            tag_mapping[category_name] = tag_id

        logger.info(f"   ğŸ“Š å…±å¤„ç† {len(tag_mapping)} ä¸ªæ ‡ç­¾")

        # ============================
        # Step 3: å»ºç«‹æœŸåˆŠ-æ ‡ç­¾å…³è”
        # ============================
        logger.info("\nğŸ“‹ Step 3: å»ºç«‹æœŸåˆŠ-æ ‡ç­¾å…³è”")

        # æŸ¥è¯¢æ‰€æœ‰æœ‰åˆ†ç±»çš„æœŸåˆŠ
        cursor.execute("""
            SELECT id, category
            FROM journals
            WHERE category IS NOT NULL AND category != ''
        """)
        journals_with_category = cursor.fetchall()
        logger.info(f"   ğŸ“Š å‘ç° {len(journals_with_category)} ä¸ªæœŸåˆŠæœ‰åˆ†ç±»")

        # åˆ›å»ºå…³è”
        association_count = 0
        for journal_id, category_name in journals_with_category:
            tag_id = tag_mapping.get(category_name)
            if tag_id:
                # æ£€æŸ¥å…³è”æ˜¯å¦å·²å­˜åœ¨
                cursor.execute("""
                    SELECT 1 FROM journal_tags
                    WHERE journal_id = ? AND tag_id = ?
                """, (journal_id, tag_id))

                if not cursor.fetchone():
                    cursor.execute("""
                        INSERT INTO journal_tags (journal_id, tag_id)
                        VALUES (?, ?)
                    """, (journal_id, tag_id))
                    association_count += 1

        logger.info(f"   âœ… åˆ›å»º {association_count} ä¸ªæœŸåˆŠ-æ ‡ç­¾å…³è”")

        # ============================
        # Step 4: é‡å»ºjournalsè¡¨ï¼ˆåˆ é™¤categoryå’Œimpact_factorå­—æ®µï¼‰
        # ============================
        logger.info("\nğŸ“‹ Step 4: é‡å»ºjournalsè¡¨ï¼ˆåˆ é™¤categoryå’Œimpact_factorå­—æ®µï¼‰")

        # è¯»å–ç°æœ‰æ•°æ®ï¼ˆæ’é™¤è¦åˆ é™¤çš„å­—æ®µï¼‰
        cursor.execute("""
            SELECT id, name, language, notes, created_at, updated_at
            FROM journals
        """)
        journals_data = cursor.fetchall()
        logger.info(f"   ğŸ“Š è¯»å–åˆ° {len(journals_data)} æ¡æœŸåˆŠæ•°æ®")

        # å¤‡ä»½æ—§è¡¨
        cursor.execute("DROP TABLE IF EXISTS journals_old")
        cursor.execute("ALTER TABLE journals RENAME TO journals_old")
        logger.info("   âœ… å¤‡ä»½æ—§è¡¨ä¸º journals_old")

        # åˆ›å»ºæ–°è¡¨ï¼ˆä¸å«categoryå’Œimpact_factorï¼‰
        cursor.execute("""
            CREATE TABLE journals (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                name TEXT NOT NULL UNIQUE,
                language TEXT NOT NULL DEFAULT 'zh',
                notes TEXT,
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                updated_at DATETIME DEFAULT CURRENT_TIMESTAMP
            )
        """)
        logger.info("   âœ… åˆ›å»ºæ–°è¡¨: journalsï¼ˆä¸å«categoryå’Œimpact_factorå­—æ®µï¼‰")

        # åˆ é™¤æ—§ç´¢å¼•ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        old_indexes = ['idx_journal_name', 'idx_journal_language', 'idx_journal_category', 'idx_journal_language_category']
        for idx in old_indexes:
            try:
                cursor.execute(f"DROP INDEX IF EXISTS {idx}")
            except:
                pass

        # åˆ›å»ºç´¢å¼•
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_journal_name ON journals(name)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_journal_language ON journals(language)")
        logger.info("   âœ… åˆ›å»ºç´¢å¼•")

        # è¿ç§»æ•°æ®
        for row in journals_data:
            cursor.execute("""
                INSERT INTO journals (id, name, language, notes, created_at, updated_at)
                VALUES (?, ?, ?, ?, ?, ?)
            """, row)
        logger.info(f"   âœ… è¿ç§» {len(journals_data)} æ¡æ•°æ®åˆ°æ–°è¡¨")

        # åˆ é™¤æ—§è¡¨
        cursor.execute("DROP TABLE journals_old")
        logger.info("   âœ… åˆ é™¤æ—§è¡¨ journals_old")

        # ============================
        # Step 5: éªŒè¯è¿ç§»ç»“æœ
        # ============================
        logger.info("\nğŸ“‹ Step 5: éªŒè¯è¿ç§»ç»“æœ")

        # éªŒè¯tagsè¡¨
        cursor.execute("SELECT COUNT(*) FROM tags")
        tags_count = cursor.fetchone()[0]
        logger.info(f"   âœ… tagsè¡¨: {tags_count} æ¡è®°å½•")

        # éªŒè¯journal_tagsè¡¨
        cursor.execute("SELECT COUNT(*) FROM journal_tags")
        associations_count = cursor.fetchone()[0]
        logger.info(f"   âœ… journal_tagså…³è”: {associations_count} æ¡è®°å½•")

        # éªŒè¯journalsè¡¨å­—æ®µ
        journals_columns = get_table_columns(cursor, 'journals')
        required_fields = ['id', 'name', 'language', 'notes', 'created_at', 'updated_at']
        removed_fields = ['category', 'impact_factor']

        all_fields_ok = True
        for field in required_fields:
            if field in journals_columns:
                logger.info(f"   âœ… journalsè¡¨.{field} å­˜åœ¨")
            else:
                logger.error(f"   âŒ journalsè¡¨.{field} ç¼ºå¤±ï¼")
                all_fields_ok = False

        for field in removed_fields:
            if field not in journals_columns:
                logger.info(f"   âœ… journalsè¡¨.{field} å·²åˆ é™¤")
            else:
                logger.error(f"   âŒ journalsè¡¨.{field} ä»ç„¶å­˜åœ¨ï¼")
                all_fields_ok = False

        if not all_fields_ok:
            conn.rollback()
            return False

        # éªŒè¯æ•°æ®å®Œæ•´æ€§
        cursor.execute("SELECT COUNT(*) FROM journals")
        journals_count = cursor.fetchone()[0]
        if journals_count == len(journals_data):
            logger.info(f"   âœ… æ•°æ®å®Œæ•´æ€§éªŒè¯é€šè¿‡ï¼ˆ{journals_count}æ¡æ•°æ®ï¼‰")
        else:
            logger.error(f"   âŒ æ•°æ®ä¸¢å¤±ï¼åŸå§‹æ•°æ®{len(journals_data)}æ¡ï¼Œç°åœ¨{journals_count}æ¡")
            conn.rollback()
            return False

        # æäº¤äº‹åŠ¡
        conn.commit()
        mark_migration_completed(db_path)

        logger.info("\n" + "=" * 70)
        logger.info("ğŸ‰ v3.0 æœŸåˆŠTagsç³»ç»Ÿåˆ›å»ºå®Œæˆï¼")
        logger.info(f"âœ… æ–°å¢è¡¨: tagsï¼ˆ{tags_count}æ¡ï¼‰")
        logger.info(f"âœ… æ–°å¢è¡¨: journal_tagsï¼ˆ{associations_count}æ¡å…³è”ï¼‰")
        logger.info(f"âœ… åˆ é™¤å­—æ®µ: categoryã€impact_factor")
        logger.info(f"âœ… ä¿ç•™æ•°æ®: {journals_count} æ¡æœŸåˆŠ")
        logger.info("âš ï¸  ä¸‹ä¸€æ­¥: æ›´æ–°åç«¯APIå’Œå‰ç«¯UI")
        logger.info("=" * 70)

        conn.close()

        return True

    except Exception as e:
        logger.error(f"è¿ç§»æ‰§è¡Œå¤±è´¥: {e}")
        logger.error(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
        logger.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {str(e)}")

        # å°è¯•å›æ»šäº‹åŠ¡
        try:
            conn.rollback()
            logger.info("äº‹åŠ¡å·²å›æ»š")
        except:
            logger.error("æ— æ³•å›æ»šäº‹åŠ¡")

        # å…³é—­è¿æ¥
        try:
            conn.close()
        except:
            pass

        logger.info(f"æ•°æ®åº“å¤‡ä»½ä½äº: {backup_path}")
        logger.error("å»ºè®®ä»å¤‡ä»½æ¢å¤æ•°æ®åº“")
        return False

if __name__ == "__main__":
    logger.info(f"å¼€å§‹æ‰§è¡Œè¿ç§»ç‰ˆæœ¬: {MIGRATION_VERSION}")
    logger.info(f"æ‰§è¡Œæ—¶é—´: {datetime.now()}")

    try:
        success = run_migration()

        if success:
            logger.info("âœ… è¿ç§»æ‰§è¡ŒæˆåŠŸ")
            print("Migration completed successfully")
            sys.exit(0)
        else:
            logger.error("âŒ è¿ç§»æ‰§è¡Œå¤±è´¥")
            print("Migration failed")
            sys.exit(1)

    except KeyboardInterrupt:
        logger.warning("è¿ç§»è¢«ç”¨æˆ·ä¸­æ–­")
        print("Migration interrupted by user")
        sys.exit(1)

    except Exception as e:
        logger.error(f"æœªé¢„æœŸçš„é”™è¯¯: {e}")
        print(f"Unexpected error: {e}")
        sys.exit(1)
