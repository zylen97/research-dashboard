# USTS Research Dashboard - Deployment Guide

æœ¬æ–‡æ¡£æä¾›USTSç§‘ç ”ç®¡ç†ç³»ç»Ÿçš„å®Œæ•´éƒ¨ç½²æŒ‡å—ï¼ŒåŒ…æ‹¬æœ¬åœ°å¼€å‘ã€ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²ã€ç›‘æ§å’Œæ•…éšœæ’é™¤ã€‚

## ğŸ“‹ ç›®å½•

- [ç¯å¢ƒè¦æ±‚](#ç¯å¢ƒè¦æ±‚)
- [æœ¬åœ°å¼€å‘éƒ¨ç½²](#æœ¬åœ°å¼€å‘éƒ¨ç½²)
- [ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²](#ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²)
- [è‡ªåŠ¨åŒ–éƒ¨ç½²](#è‡ªåŠ¨åŒ–éƒ¨ç½²)
- [ç¯å¢ƒé…ç½®](#ç¯å¢ƒé…ç½®)
- [æ•°æ®åº“ç®¡ç†](#æ•°æ®åº“ç®¡ç†)
- [æ€§èƒ½ç›‘æ§](#æ€§èƒ½ç›‘æ§)
- [æ•…éšœæ’é™¤](#æ•…éšœæ’é™¤)
- [å®‰å…¨é…ç½®](#å®‰å…¨é…ç½®)
- [å¤‡ä»½ç­–ç•¥](#å¤‡ä»½ç­–ç•¥)

## ğŸ”§ ç¯å¢ƒè¦æ±‚

### åŸºç¡€ç¯å¢ƒ
- **æ“ä½œç³»ç»Ÿ**: Ubuntu 20.04+ / CentOS 8+ / macOS 12+
- **Python**: 3.8+ (æ¨è 3.9+)
- **Node.js**: 16+ (æ¨è 18 LTS)
- **Git**: 2.25+

### ç”Ÿäº§ç¯å¢ƒé™„åŠ è¦æ±‚
- **Nginx**: 1.18+
- **Systemd**: 242+
- **å†…å­˜**: æœ€å°2GBï¼Œæ¨è4GB+
- **å­˜å‚¨**: æœ€å°10GBï¼Œæ¨è50GB+
- **ç½‘ç»œ**: ç¨³å®šçš„äº’è”ç½‘è¿æ¥

### æ¨èé…ç½®
```bash
# CPUæ ¸å¿ƒæ•°
min: 2 cores
recommended: 4+ cores

# å†…å­˜
min: 2GB RAM
recommended: 8GB+ RAM

# å­˜å‚¨
min: 20GB SSD
recommended: 100GB+ SSD
```

## ğŸ  æœ¬åœ°å¼€å‘éƒ¨ç½²

### æ–¹å¼ä¸€ï¼šä¸€é”®å¯åŠ¨ï¼ˆæ¨èï¼‰

```bash
# 1. å…‹éš†é¡¹ç›®
git clone https://github.com/zylen97/research-dashboard.git
cd research-dashboard

# 2. ç»™äºˆæ‰§è¡Œæƒé™
chmod +x start-dev.sh

# 3. ä¸€é”®å¯åŠ¨
./start-dev.sh
```

### æ–¹å¼äºŒï¼šåˆ†æ­¥éƒ¨ç½²

#### åç«¯éƒ¨ç½²
```bash
# 1. è¿›å…¥åç«¯ç›®å½•
cd backend

# 2. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼ˆæ¨èï¼‰
python -m venv venv
source venv/bin/activate  # Linux/macOS
# venv\Scripts\activate  # Windows

# 3. å®‰è£…ä¾èµ–
pip install -r requirements.txt

# 4. åˆå§‹åŒ–æ•°æ®åº“
python scripts/init_db.py

# 5. è¿è¡Œå¼€å‘æœåŠ¡å™¨
python main.py
```

#### å‰ç«¯éƒ¨ç½²
```bash
# 1. æ‰“å¼€æ–°ç»ˆç«¯ï¼Œè¿›å…¥å‰ç«¯ç›®å½•
cd frontend

# 2. å®‰è£…ä¾èµ–
npm install
# æˆ–ä½¿ç”¨yarn
yarn install

# 3. å¯åŠ¨å¼€å‘æœåŠ¡å™¨
npm start
# æˆ–
yarn start
```

### è®¿é—®åº”ç”¨
- **å‰ç«¯**: http://localhost:3001
- **åç«¯API**: http://localhost:8080
- **APIæ–‡æ¡£**: http://localhost:8080/docs

### é»˜è®¤è´¦æˆ·
| ç”¨æˆ·å | å¯†ç  | è¯´æ˜ |
|--------|------|------|
| zl     | 123  | æµ‹è¯•ç”¨æˆ·1 |
| zz     | 123  | æµ‹è¯•ç”¨æˆ·2 |
| yq     | 123  | æµ‹è¯•ç”¨æˆ·3 |
| dj     | 123  | æµ‹è¯•ç”¨æˆ·4 |

## ğŸŒ ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²

### æœåŠ¡å™¨å‡†å¤‡

#### 1. ç³»ç»Ÿæ›´æ–°
```bash
# Ubuntu/Debian
sudo apt update && sudo apt upgrade -y

# CentOS/RHEL
sudo yum update -y
```

#### 2. å®‰è£…åŸºç¡€è½¯ä»¶
```bash
# Ubuntu/Debian
sudo apt install -y python3 python3-pip python3-venv nodejs npm nginx git

# CentOS/RHEL
sudo yum install -y python3 python3-pip nodejs npm nginx git
```

#### 3. å®‰è£…Node.js LTSï¼ˆå¦‚æœç‰ˆæœ¬è¿‡ä½ï¼‰
```bash
# ä½¿ç”¨NodeSourceä»“åº“
curl -fsSL https://deb.nodesource.com/setup_18.x | sudo -E bash -
sudo apt-get install -y nodejs
```

### åº”ç”¨éƒ¨ç½²

#### 1. é¡¹ç›®å…‹éš†
```bash
# åˆ›å»ºåº”ç”¨ç›®å½•
sudo mkdir -p /opt/research-dashboard
sudo chown $USER:$USER /opt/research-dashboard

# å…‹éš†é¡¹ç›®
cd /opt
git clone https://github.com/zylen97/research-dashboard.git
cd research-dashboard
```

#### 2. åç«¯éƒ¨ç½²
```bash
# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
cd backend
python3 -m venv venv
source venv/bin/activate

# å®‰è£…ä¾èµ–
pip install -r requirements.txt

# è®¾ç½®ç¯å¢ƒå˜é‡
export ENVIRONMENT=production
export SECRET_KEY="your-super-secret-key-change-in-production"
export DATABASE_URL="sqlite:///./data/research_dashboard_prod.db"

# åˆå§‹åŒ–ç”Ÿäº§æ•°æ®åº“
python scripts/init_db.py

# æµ‹è¯•å¯åŠ¨
python main.py
```

#### 3. å‰ç«¯æ„å»º
```bash
# è¿›å…¥å‰ç«¯ç›®å½•
cd ../frontend

# å®‰è£…ä¾èµ–
npm install --production

# æ„å»ºç”Ÿäº§ç‰ˆæœ¬
npm run build

# æ„å»ºæ–‡ä»¶ä½äº build/ ç›®å½•
```

### SystemdæœåŠ¡é…ç½®

#### åˆ›å»ºåç«¯æœåŠ¡
```bash
sudo nano /etc/systemd/system/research-backend.service
```

```ini
[Unit]
Description=USTS Research Dashboard Backend
After=network.target

[Service]
Type=simple
User=www-data
Group=www-data
WorkingDirectory=/opt/research-dashboard/backend
Environment=ENVIRONMENT=production
Environment=SECRET_KEY=your-super-secret-key-change-in-production
Environment=DATABASE_URL=sqlite:///./data/research_dashboard_prod.db
Environment=CORS_ORIGINS=http://45.149.156.216:3001
ExecStart=/opt/research-dashboard/backend/venv/bin/python main.py
Restart=always
RestartSec=3

[Install]
WantedBy=multi-user.target
```

#### å¯åŠ¨åç«¯æœåŠ¡
```bash
# é‡æ–°åŠ è½½systemdé…ç½®
sudo systemctl daemon-reload

# å¯ç”¨æœåŠ¡ï¼ˆå¼€æœºè‡ªå¯ï¼‰
sudo systemctl enable research-backend

# å¯åŠ¨æœåŠ¡
sudo systemctl start research-backend

# æ£€æŸ¥çŠ¶æ€
sudo systemctl status research-backend
```

### Nginxé…ç½®

#### åˆ›å»ºç«™ç‚¹é…ç½®
```bash
sudo nano /etc/nginx/sites-available/research-dashboard
```

```nginx
# å‰ç«¯é…ç½®
server {
    listen 3001;
    server_name 45.149.156.216;
    
    root /opt/research-dashboard/frontend/build;
    index index.html;
    
    # å¯ç”¨Gzipå‹ç¼©
    gzip on;
    gzip_vary on;
    gzip_min_length 10240;
    gzip_proxied expired no-cache no-store private must-revalidate auth;
    gzip_types text/plain text/css text/xml text/javascript application/javascript application/xml+rss application/json;
    
    # é™æ€èµ„æºç¼“å­˜
    location ~* \.(js|css|png|jpg|jpeg|gif|ico|svg)$ {
        expires 1y;
        add_header Cache-Control "public, immutable";
        try_files $uri =404;
    }
    
    # Reactè·¯ç”±æ”¯æŒ
    location / {
        try_files $uri $uri/ /index.html;
        add_header Cache-Control "no-cache, no-store, must-revalidate";
    }
    
    # APIä»£ç†
    location /api {
        proxy_pass http://127.0.0.1:8080;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        
        # è¶…æ—¶é…ç½®
        proxy_connect_timeout 60s;
        proxy_send_timeout 60s;
        proxy_read_timeout 60s;
    }
    
    # Swaggeræ–‡æ¡£ä»£ç†
    location /docs {
        proxy_pass http://127.0.0.1:8080;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }
}

# åç«¯ç›´æ¥è®¿é—®ï¼ˆå¯é€‰ï¼‰
server {
    listen 8080;
    server_name 45.149.156.216;
    
    location / {
        proxy_pass http://127.0.0.1:8000;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }
}
```

#### å¯ç”¨ç«™ç‚¹
```bash
# åˆ›å»ºè½¯é“¾æ¥
sudo ln -s /etc/nginx/sites-available/research-dashboard /etc/nginx/sites-enabled/

# æµ‹è¯•é…ç½®
sudo nginx -t

# é‡æ–°åŠ è½½é…ç½®
sudo systemctl reload nginx

# æ£€æŸ¥çŠ¶æ€
sudo systemctl status nginx
```

### SSL/HTTPSé…ç½®ï¼ˆæ¨èï¼‰

#### ä½¿ç”¨Let's Encrypt
```bash
# å®‰è£…Certbot
sudo apt install -y certbot python3-certbot-nginx

# è·å–SSLè¯ä¹¦
sudo certbot --nginx -d your-domain.com

# è‡ªåŠ¨ç»­æœŸ
sudo crontab -e
# æ·»åŠ ä»¥ä¸‹è¡Œï¼š
0 12 * * * /usr/bin/certbot renew --quiet
```

## ğŸš€ è‡ªåŠ¨åŒ–éƒ¨ç½²

### GitHub Actionséƒ¨ç½²

é¡¹ç›®å·²é…ç½®GitHub Actionsè‡ªåŠ¨éƒ¨ç½²ï¼Œæ¨é€åˆ°mainåˆ†æ”¯æ—¶è‡ªåŠ¨è§¦å‘ã€‚

#### éƒ¨ç½²è„šæœ¬ä½¿ç”¨
```bash
# è‡ªåŠ¨æ£€æµ‹ä¿®æ”¹ç±»å‹å¹¶éƒ¨ç½²
./deploy-scripts/deploy.sh

# æŒ‡å®šéƒ¨ç½²ç±»å‹
./deploy-scripts/deploy.sh --frontend  # ä»…å‰ç«¯
./deploy-scripts/deploy.sh --backend   # ä»…åç«¯  
./deploy-scripts/deploy.sh --all       # å‰åç«¯
```

#### éƒ¨ç½²æµç¨‹
1. **ä»£ç æ¨é€** â†’ GitHubä»“åº“
2. **GitHub Actions** â†’ è‡ªåŠ¨æ„å»ºå’Œæµ‹è¯•
3. **éƒ¨ç½²åˆ°VPS** â†’ è‡ªåŠ¨æ›´æ–°ç”Ÿäº§ç¯å¢ƒ
4. **æœåŠ¡é‡å¯** â†’ è‡ªåŠ¨é‡å¯ç›¸å…³æœåŠ¡
5. **å¥åº·æ£€æŸ¥** â†’ éªŒè¯éƒ¨ç½²æˆåŠŸ

### æ‰‹åŠ¨éƒ¨ç½²æ›´æ–°

```bash
# 1. è¿›å…¥é¡¹ç›®ç›®å½•
cd /opt/research-dashboard

# 2. å¤‡ä»½æ•°æ®åº“
cp backend/data/research_dashboard_prod.db backend/data/research_dashboard_prod.db.backup

# 3. æ›´æ–°ä»£ç 
git pull origin main

# 4. æ›´æ–°åç«¯ä¾èµ–
cd backend
source venv/bin/activate
pip install -r requirements.txt

# 5. è¿è¡Œæ•°æ®åº“è¿ç§»
python migrations/migration.py

# 6. é‡å¯åç«¯æœåŠ¡
sudo systemctl restart research-backend

# 7. æ›´æ–°å‰ç«¯
cd ../frontend
npm install --production
npm run build

# 8. é‡æ–°åŠ è½½Nginx
sudo systemctl reload nginx

# 9. éªŒè¯éƒ¨ç½²
curl -f http://localhost:8080/api/auth/me || echo "Backend failed"
curl -f http://localhost:3001 || echo "Frontend failed"
```

## âš™ï¸ ç¯å¢ƒé…ç½®

### ç¯å¢ƒå˜é‡

#### å¼€å‘ç¯å¢ƒ (.env.development)
```bash
# åŸºç¡€é…ç½®
ENVIRONMENT=development
SECRET_KEY=development-secret-key-change-in-production
DATABASE_URL=sqlite:///./data/research_dashboard_dev.db
CORS_ORIGINS=http://localhost:3001

# AIé…ç½®
AI_BATCH_SIZE_LIMIT=10
AI_MAX_CONCURRENT=3
AI_MAX_RETRIES=2

# æ€§èƒ½é…ç½®
HTTP_MAX_CONNECTIONS=50
HTTP_KEEPALIVE_CONNECTIONS=10
ENABLE_HTTP2=true
```

#### ç”Ÿäº§ç¯å¢ƒ (.env.production)
```bash
# åŸºç¡€é…ç½®
ENVIRONMENT=production
SECRET_KEY=your-super-secret-key-change-in-production-must-be-long
DATABASE_URL=sqlite:///./data/research_dashboard_prod.db
CORS_ORIGINS=http://45.149.156.216:3001,https://your-domain.com

# AIé…ç½®
AI_BATCH_SIZE_LIMIT=50
AI_MAX_CONCURRENT=5
AI_MAX_RETRIES=2

# æ€§èƒ½é…ç½®
HTTP_MAX_CONNECTIONS=100
HTTP_KEEPALIVE_CONNECTIONS=20
ENABLE_HTTP2=true

# æ—¥å¿—é…ç½®
LOG_LEVEL=INFO
LOG_FILE=/opt/research-dashboard/backend/logs/app.log
```

### ç³»ç»Ÿé…ç½®æ–‡ä»¶

#### backend/app/core/config.py
```python
import os
from typing import List
from pydantic import BaseSettings

class Settings(BaseSettings):
    # åŸºç¡€è®¾ç½®
    environment: str = os.getenv("ENVIRONMENT", "development")
    secret_key: str = os.getenv("SECRET_KEY", "your-secret-key")
    database_url: str = os.getenv("DATABASE_URL", "sqlite:///./data/research_dashboard.db")
    
    # CORSè®¾ç½®
    cors_origins: List[str] = os.getenv("CORS_ORIGINS", "http://localhost:3001").split(",")
    
    # JWTè®¾ç½®
    jwt_algorithm: str = "HS256"
    jwt_expiration_hours: int = 24 * 7  # 7å¤©
    
    # AIæ‰¹é‡å¤„ç†é…ç½®
    ai_batch_size_limit: int = int(os.getenv("AI_BATCH_SIZE_LIMIT", "50"))
    ai_max_concurrent: int = int(os.getenv("AI_MAX_CONCURRENT", "5"))
    ai_max_retries: int = int(os.getenv("AI_MAX_RETRIES", "2"))
    
    class Config:
        env_file = f".env.{os.getenv('ENVIRONMENT', 'development')}"

settings = Settings()
```

## ğŸ—„ï¸ æ•°æ®åº“ç®¡ç†

### æ•°æ®åº“åˆå§‹åŒ–

#### å¼€å‘ç¯å¢ƒ
```bash
cd backend
python scripts/init_db.py
```

#### ç”Ÿäº§ç¯å¢ƒ
```bash
cd backend
export ENVIRONMENT=production
python scripts/init_db.py
```

### æ•°æ®åº“è¿ç§»

#### åˆ›å»ºè¿ç§»
```bash
cd backend/migrations

# ç¼–è¾‘ migration.py
nano migration.py

# æ›´æ–°ç‰ˆæœ¬å·
MIGRATION_VERSION = "v1.4_add_new_feature"

# æ·»åŠ è¿ç§»SQL
def run_migration(cursor):
    cursor.execute("ALTER TABLE users ADD COLUMN new_field VARCHAR(255)")
```

#### æ‰§è¡Œè¿ç§»
```bash
cd backend
python migrations/migration.py
```

#### è¿ç§»éªŒè¯
```bash
# æ£€æŸ¥è¿ç§»çŠ¶æ€
sqlite3 data/research_dashboard_prod.db "SELECT * FROM migration_history ORDER BY executed_at DESC LIMIT 5;"

# éªŒè¯è¡¨ç»“æ„
sqlite3 data/research_dashboard_prod.db ".schema table_name"
```

### æ•°æ®åº“å¤‡ä»½å’Œæ¢å¤

#### è‡ªåŠ¨å¤‡ä»½é…ç½®
```bash
# åˆ›å»ºå¤‡ä»½è„šæœ¬
sudo nano /opt/research-dashboard/scripts/backup_db.sh
```

```bash
#!/bin/bash
BACKUP_DIR="/opt/research-dashboard/backend/backups/production"
DB_PATH="/opt/research-dashboard/backend/data/research_dashboard_prod.db"
TIMESTAMP=$(date +"%Y%m%d_%H%M%S")
BACKUP_FILE="$BACKUP_DIR/backup_${TIMESTAMP}.db"

# åˆ›å»ºå¤‡ä»½ç›®å½•
mkdir -p $BACKUP_DIR

# åˆ›å»ºå¤‡ä»½
sqlite3 $DB_PATH ".backup $BACKUP_FILE"

# å‹ç¼©å¤‡ä»½
gzip $BACKUP_FILE

# æ¸…ç†æ—§å¤‡ä»½ï¼ˆä¿ç•™7ä¸ªæœ€æ–°çš„ï¼‰
ls -t $BACKUP_DIR/*.gz | tail -n +8 | xargs rm -f

echo "Backup created: ${BACKUP_FILE}.gz"
```

#### è®¾ç½®è‡ªåŠ¨å¤‡ä»½
```bash
# ç»™äºˆæ‰§è¡Œæƒé™
chmod +x /opt/research-dashboard/scripts/backup_db.sh

# æ·»åŠ åˆ°crontab
crontab -e

# æ¯å¤©å‡Œæ™¨2ç‚¹è‡ªåŠ¨å¤‡ä»½
0 2 * * * /opt/research-dashboard/scripts/backup_db.sh
```

#### æ‰‹åŠ¨æ¢å¤å¤‡ä»½
```bash
cd backend

# åœæ­¢æœåŠ¡
sudo systemctl stop research-backend

# å¤‡ä»½å½“å‰æ•°æ®åº“
cp data/research_dashboard_prod.db data/research_dashboard_prod.db.before_restore

# è§£å‹å¤‡ä»½æ–‡ä»¶
gunzip backups/production/backup_20250722_020000.db.gz

# æ¢å¤æ•°æ®åº“
cp backups/production/backup_20250722_020000.db data/research_dashboard_prod.db

# å¯åŠ¨æœåŠ¡
sudo systemctl start research-backend

# éªŒè¯æ¢å¤
curl -f http://localhost:8080/api/auth/me
```

## ğŸ“Š æ€§èƒ½ç›‘æ§

### ç³»ç»Ÿç›‘æ§

#### 1. æœåŠ¡çŠ¶æ€ç›‘æ§
```bash
# æ£€æŸ¥åç«¯æœåŠ¡çŠ¶æ€
sudo systemctl status research-backend

# æ£€æŸ¥NginxçŠ¶æ€
sudo systemctl status nginx

# æ£€æŸ¥æœåŠ¡æ—¥å¿—
sudo journalctl -u research-backend -f
sudo journalctl -u nginx -f
```

#### 2. èµ„æºä½¿ç”¨ç›‘æ§
```bash
# ç³»ç»Ÿèµ„æº
htop
free -h
df -h

# ç½‘ç»œè¿æ¥
netstat -tulnp | grep :8080
ss -tulnp | grep :3001

# è¿›ç¨‹ç›‘æ§
ps aux | grep python
ps aux | grep nginx
```

### åº”ç”¨ç›‘æ§

#### 1. APIå¥åº·æ£€æŸ¥
```bash
# åˆ›å»ºå¥åº·æ£€æŸ¥è„šæœ¬
nano /opt/research-dashboard/scripts/health_check.sh
```

```bash
#!/bin/bash
API_URL="http://localhost:8080"
FRONTEND_URL="http://localhost:3001"

# æ£€æŸ¥åç«¯API
if curl -f -s "$API_URL/docs" > /dev/null; then
    echo "âœ… Backend API is healthy"
else
    echo "âŒ Backend API is down"
    exit 1
fi

# æ£€æŸ¥å‰ç«¯
if curl -f -s "$FRONTEND_URL" > /dev/null; then
    echo "âœ… Frontend is healthy"  
else
    echo "âŒ Frontend is down"
    exit 1
fi

# æ£€æŸ¥æ•°æ®åº“è¿æ¥ï¼ˆé€šè¿‡APIï¼‰
if curl -f -s "$API_URL/api/backup/stats" > /dev/null; then
    echo "âœ… Database connection is healthy"
else
    echo "âŒ Database connection failed"
    exit 1
fi

echo "ğŸ‰ All systems are healthy"
```

#### 2. è‡ªåŠ¨ç›‘æ§è„šæœ¬
```bash
# è®¾ç½®å®šæ—¶å¥åº·æ£€æŸ¥
chmod +x /opt/research-dashboard/scripts/health_check.sh

# æ¯5åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
crontab -e
*/5 * * * * /opt/research-dashboard/scripts/health_check.sh >> /var/log/research-health.log 2>&1
```

#### 3. æ€§èƒ½æŒ‡æ ‡ç›‘æ§
```bash
# æ£€æŸ¥AIæ‰¹é‡åŒ¹é…æ€§èƒ½
curl -s "http://localhost:8080/api/literature/batch-match/stats" | jq

# æ£€æŸ¥æ•°æ®åº“å¤§å°
du -h backend/data/research_dashboard_prod.db

# æ£€æŸ¥å¤‡ä»½çŠ¶æ€
ls -lh backend/backups/production/
```

### æ—¥å¿—ç®¡ç†

#### 1. æ—¥å¿—é…ç½®
```python
# backend/app/core/logging_config.py
import logging
import logging.handlers
import os

def setup_logging():
    log_dir = "logs"
    os.makedirs(log_dir, exist_ok=True)
    
    # åˆ›å»ºformatter
    formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    # æ–‡ä»¶å¤„ç†å™¨ï¼ˆè½®è½¬ï¼‰
    file_handler = logging.handlers.RotatingFileHandler(
        os.path.join(log_dir, 'app.log'),
        maxBytes=10*1024*1024,  # 10MB
        backupCount=5
    )
    file_handler.setFormatter(formatter)
    file_handler.setLevel(logging.INFO)
    
    # æ§åˆ¶å°å¤„ç†å™¨
    console_handler = logging.StreamHandler()
    console_handler.setFormatter(formatter)
    console_handler.setLevel(logging.INFO)
    
    # é…ç½®root logger
    root_logger = logging.getLogger()
    root_logger.setLevel(logging.INFO)
    root_logger.addHandler(file_handler)
    root_logger.addHandler(console_handler)
```

#### 2. æ—¥å¿—æŸ¥çœ‹
```bash
# å®æ—¶æŸ¥çœ‹åº”ç”¨æ—¥å¿—
tail -f backend/logs/app.log

# æŸ¥çœ‹ç³»ç»ŸæœåŠ¡æ—¥å¿—
sudo journalctl -u research-backend -f

# æŸ¥çœ‹Nginxè®¿é—®æ—¥å¿—
sudo tail -f /var/log/nginx/access.log

# æŸ¥çœ‹Nginxé”™è¯¯æ—¥å¿—
sudo tail -f /var/log/nginx/error.log
```

## ğŸš¨ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

#### 1. ç«¯å£å ç”¨
```bash
# æ£€æŸ¥ç«¯å£å ç”¨
sudo lsof -i :8080
sudo lsof -i :3001

# ç»ˆæ­¢å ç”¨è¿›ç¨‹
sudo kill -9 <PID>

# æˆ–ä½¿ç”¨fuser
sudo fuser -k 8080/tcp
```

#### 2. æœåŠ¡å¯åŠ¨å¤±è´¥
```bash
# æŸ¥çœ‹æœåŠ¡çŠ¶æ€
sudo systemctl status research-backend

# æŸ¥çœ‹è¯¦ç»†æ—¥å¿—
sudo journalctl -u research-backend -n 50

# æ‰‹åŠ¨å¯åŠ¨æµ‹è¯•
cd /opt/research-dashboard/backend
source venv/bin/activate
python main.py
```

#### 3. æ•°æ®åº“è¿æ¥é—®é¢˜
```bash
# æ£€æŸ¥æ•°æ®åº“æ–‡ä»¶æƒé™
ls -la backend/data/

# ä¿®å¤æƒé™
sudo chown -R www-data:www-data backend/data/
sudo chmod 644 backend/data/*.db

# æµ‹è¯•æ•°æ®åº“è¿æ¥
sqlite3 backend/data/research_dashboard_prod.db ".tables"
```

#### 4. Nginxé…ç½®é—®é¢˜
```bash
# æµ‹è¯•é…ç½®æ–‡ä»¶
sudo nginx -t

# æ£€æŸ¥é…ç½®è¯­æ³•
sudo nginx -T

# é‡æ–°åŠ è½½é…ç½®
sudo systemctl reload nginx
```

#### 5. å‰ç«¯æ„å»ºé—®é¢˜
```bash
# æ¸…ç†ç¼“å­˜
cd frontend
rm -rf node_modules package-lock.json
npm install

# é‡æ–°æ„å»º
npm run build

# æ£€æŸ¥æ„å»ºæ–‡ä»¶
ls -la build/
```

### æ€§èƒ½é—®é¢˜æ’æŸ¥

#### 1. æ•°æ®åº“æ€§èƒ½
```bash
# æ£€æŸ¥æ•°æ®åº“å¤§å°
du -h backend/data/research_dashboard_prod.db

# åˆ†ææŸ¥è¯¢æ€§èƒ½
sqlite3 backend/data/research_dashboard_prod.db "EXPLAIN QUERY PLAN SELECT * FROM literature WHERE user_id = 1;"

# æ£€æŸ¥ç´¢å¼•ä½¿ç”¨
sqlite3 backend/data/research_dashboard_prod.db ".indices"
```

#### 2. APIå“åº”æ—¶é—´
```bash
# æµ‹è¯•APIå“åº”æ—¶é—´
time curl -s "http://localhost:8080/api/research/"

# ä½¿ç”¨abè¿›è¡Œå‹åŠ›æµ‹è¯•
ab -n 100 -c 10 http://localhost:8080/api/research/

# æ£€æŸ¥ç³»ç»Ÿè´Ÿè½½
uptime
iostat 1 5
```

#### 3. å†…å­˜ä½¿ç”¨
```bash
# æ£€æŸ¥Pythonè¿›ç¨‹å†…å­˜ä½¿ç”¨
ps aux | grep python | head -1; ps aux | grep python | grep -v grep | sort -nrk 4

# æ£€æŸ¥ç³»ç»Ÿå†…å­˜
free -h
cat /proc/meminfo
```

### ç´§æ€¥æ¢å¤ç¨‹åº

#### 1. æœåŠ¡å¿«é€Ÿé‡å¯
```bash
#!/bin/bash
# ç´§æ€¥é‡å¯è„šæœ¬ï¼šemergency_restart.sh

echo "ğŸš¨ Emergency restart initiated..."

# åœæ­¢æœåŠ¡
sudo systemctl stop research-backend
sudo systemctl stop nginx

# ç­‰å¾…è¿›ç¨‹å®Œå…¨åœæ­¢
sleep 5

# æ£€æŸ¥å¹¶æ¸…ç†åƒµå°¸è¿›ç¨‹
sudo pkill -f "python.*main.py"
sudo pkill -f nginx

# é‡å¯æœåŠ¡
sudo systemctl start research-backend
sudo systemctl start nginx

# ç­‰å¾…æœåŠ¡å¯åŠ¨
sleep 10

# å¥åº·æ£€æŸ¥
if curl -f -s "http://localhost:8080/docs" > /dev/null; then
    echo "âœ… Backend restarted successfully"
else
    echo "âŒ Backend restart failed"
    exit 1
fi

if curl -f -s "http://localhost:3001" > /dev/null; then
    echo "âœ… Frontend accessible"
else
    echo "âŒ Frontend not accessible"
    exit 1
fi

echo "ğŸ‰ Emergency restart completed successfully"
```

#### 2. æ•°æ®åº“ç´§æ€¥æ¢å¤
```bash
#!/bin/bash
# æ•°æ®åº“ç´§æ€¥æ¢å¤è„šæœ¬ï¼šemergency_db_restore.sh

BACKUP_DIR="/opt/research-dashboard/backend/backups/production"
LATEST_BACKUP=$(ls -t $BACKUP_DIR/*.gz | head -1)

if [ -z "$LATEST_BACKUP" ]; then
    echo "âŒ No backup found"
    exit 1
fi

echo "ğŸ”„ Restoring from: $LATEST_BACKUP"

# åœæ­¢åç«¯æœåŠ¡
sudo systemctl stop research-backend

# å¤‡ä»½å½“å‰æ•°æ®åº“
cp backend/data/research_dashboard_prod.db backend/data/emergency_backup_$(date +%Y%m%d_%H%M%S).db

# æ¢å¤å¤‡ä»½
gunzip -c "$LATEST_BACKUP" > backend/data/research_dashboard_prod.db

# å¯åŠ¨æœåŠ¡
sudo systemctl start research-backend

echo "âœ… Database restored successfully"
```

## ğŸ”’ å®‰å…¨é…ç½®

### SSL/TLSé…ç½®

#### å¼ºåŒ–SSLé…ç½®
```nginx
# åœ¨Nginxé…ç½®ä¸­æ·»åŠ 
server {
    listen 443 ssl http2;
    server_name your-domain.com;
    
    # SSLè¯ä¹¦
    ssl_certificate /etc/letsencrypt/live/your-domain.com/fullchain.pem;
    ssl_certificate_key /etc/letsencrypt/live/your-domain.com/privkey.pem;
    
    # SSLé…ç½®
    ssl_protocols TLSv1.2 TLSv1.3;
    ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384;
    ssl_prefer_server_ciphers off;
    
    # HSTS
    add_header Strict-Transport-Security "max-age=63072000" always;
    
    # å…¶ä»–å®‰å…¨å¤´
    add_header X-Frame-Options DENY;
    add_header X-Content-Type-Options nosniff;
    add_header Referrer-Policy "strict-origin-when-cross-origin";
    
    # å…¶ä½™é…ç½®...
}

# HTTPé‡å®šå‘åˆ°HTTPS
server {
    listen 80;
    server_name your-domain.com;
    return 301 https://$server_name$request_uri;
}
```

### é˜²ç«å¢™é…ç½®

#### Ubuntu/Debian (ufw)
```bash
# å®‰è£…ufw
sudo apt install ufw

# é»˜è®¤ç­–ç•¥
sudo ufw default deny incoming
sudo ufw default allow outgoing

# å…è®¸SSH
sudo ufw allow ssh

# å…è®¸HTTP/HTTPS
sudo ufw allow 80
sudo ufw allow 443

# å…è®¸åº”ç”¨ç«¯å£
sudo ufw allow 3001
sudo ufw allow 8080

# å¯ç”¨é˜²ç«å¢™
sudo ufw enable

# æ£€æŸ¥çŠ¶æ€
sudo ufw status verbose
```

### ç³»ç»Ÿå®‰å…¨åŠ å›º

#### 1. ç”¨æˆ·æƒé™
```bash
# åˆ›å»ºä¸“ç”¨ç”¨æˆ·
sudo useradd -r -s /bin/false research-app
sudo usermod -a -G www-data research-app

# è®¾ç½®ç›®å½•æƒé™
sudo chown -R research-app:www-data /opt/research-dashboard
sudo chmod -R 750 /opt/research-dashboard

# æ•°æ®ç›®å½•æƒé™
sudo chmod 700 /opt/research-dashboard/backend/data
sudo chmod 600 /opt/research-dashboard/backend/data/*.db
```

#### 2. æ•æ„Ÿæ–‡ä»¶ä¿æŠ¤
```bash
# ç¯å¢ƒå˜é‡æ–‡ä»¶
chmod 600 backend/.env.*

# ç§é’¥å’Œè¯ä¹¦
chmod 600 /etc/ssl/private/*
chmod 644 /etc/ssl/certs/*
```

## ğŸ’¾ å¤‡ä»½ç­–ç•¥

### å®Œæ•´å¤‡ä»½æ–¹æ¡ˆ

#### 1. æ•°æ®å¤‡ä»½
```bash
# åˆ›å»ºå®Œæ•´å¤‡ä»½è„šæœ¬
nano /opt/research-dashboard/scripts/full_backup.sh
```

```bash
#!/bin/bash
BACKUP_ROOT="/opt/backups/research-dashboard"
TIMESTAMP=$(date +"%Y%m%d_%H%M%S")
BACKUP_DIR="$BACKUP_ROOT/$TIMESTAMP"

mkdir -p "$BACKUP_DIR"

# å¤‡ä»½æ•°æ®åº“
cp /opt/research-dashboard/backend/data/*.db "$BACKUP_DIR/"

# å¤‡ä»½ä¸Šä¼ æ–‡ä»¶
tar -czf "$BACKUP_DIR/uploads.tar.gz" /opt/research-dashboard/backend/uploads/

# å¤‡ä»½é…ç½®æ–‡ä»¶
cp /opt/research-dashboard/backend/.env.* "$BACKUP_DIR/"
cp /etc/nginx/sites-available/research-dashboard "$BACKUP_DIR/"
cp /etc/systemd/system/research-backend.service "$BACKUP_DIR/"

# åˆ›å»ºå¤‡ä»½æ¸…å•
echo "Backup created: $TIMESTAMP" > "$BACKUP_DIR/backup_info.txt"
echo "Database files:" >> "$BACKUP_DIR/backup_info.txt"
ls -lh "$BACKUP_DIR"/*.db >> "$BACKUP_DIR/backup_info.txt"

# æ¸…ç†æ—§å¤‡ä»½ï¼ˆä¿ç•™30å¤©ï¼‰
find "$BACKUP_ROOT" -type d -mtime +30 -exec rm -rf {} \;

echo "Full backup completed: $BACKUP_DIR"
```

#### 2. è¿œç¨‹å¤‡ä»½
```bash
# åŒæ­¥åˆ°è¿œç¨‹æœåŠ¡å™¨
rsync -avz --delete "$BACKUP_DIR/" user@remote-server:/backups/research-dashboard/

# æˆ–ä¸Šä¼ åˆ°äº‘å­˜å‚¨ï¼ˆç¤ºä¾‹ï¼šAWS S3ï¼‰
aws s3 sync "$BACKUP_DIR/" s3://your-backup-bucket/research-dashboard/$TIMESTAMP/
```

### å¤‡ä»½æµ‹è¯•å’ŒéªŒè¯

#### è‡ªåŠ¨å¤‡ä»½éªŒè¯è„šæœ¬
```bash
#!/bin/bash
# éªŒè¯å¤‡ä»½å®Œæ•´æ€§

BACKUP_FILE="/opt/research-dashboard/backend/backups/production/backup_$(date +%Y%m%d)*.db.gz"

if [ -f "$BACKUP_FILE" ]; then
    # è§£å‹å¹¶æµ‹è¯•
    gunzip -t "$BACKUP_FILE" && echo "âœ… Backup file integrity OK" || echo "âŒ Backup file corrupted"
    
    # æµ‹è¯•æ•°æ®åº“ç»“æ„
    TEMP_DB="/tmp/test_restore_$(date +%s).db"
    gunzip -c "$BACKUP_FILE" > "$TEMP_DB"
    
    if sqlite3 "$TEMP_DB" ".tables" > /dev/null 2>&1; then
        echo "âœ… Database structure OK"
        rm "$TEMP_DB"
    else
        echo "âŒ Database structure damaged"
    fi
else
    echo "âŒ No backup found for today"
fi
```

## ğŸ“‹ éƒ¨ç½²æ£€æŸ¥æ¸…å•

### éƒ¨ç½²å‰æ£€æŸ¥
- [ ] æœåŠ¡å™¨èµ„æºå……è¶³ï¼ˆCPUã€å†…å­˜ã€å­˜å‚¨ï¼‰
- [ ] å¿…è¦è½¯ä»¶å·²å®‰è£…ï¼ˆPythonã€Node.jsã€Nginxï¼‰
- [ ] é˜²ç«å¢™è§„åˆ™é…ç½®æ­£ç¡®
- [ ] SSLè¯ä¹¦å·²é…ç½®ï¼ˆç”Ÿäº§ç¯å¢ƒï¼‰
- [ ] ç¯å¢ƒå˜é‡å·²è®¾ç½®
- [ ] æ•°æ®åº“å¤‡ä»½å·²åˆ›å»º

### éƒ¨ç½²åéªŒè¯
- [ ] å‰ç«¯å¯æ­£å¸¸è®¿é—®
- [ ] åç«¯APIæ­£å¸¸å“åº”
- [ ] ç”¨æˆ·è®¤è¯åŠŸèƒ½æ­£å¸¸
- [ ] æ•°æ®åº“è¿æ¥æ­£å¸¸
- [ ] æ–‡ä»¶ä¸Šä¼ åŠŸèƒ½æ­£å¸¸
- [ ] AIæ‰¹é‡åŒ¹é…åŠŸèƒ½æ­£å¸¸
- [ ] ç³»ç»Ÿé…ç½®åŠŸèƒ½æ­£å¸¸
- [ ] å¤‡ä»½åŠŸèƒ½æ­£å¸¸
- [ ] æ—¥å¿—è®°å½•æ­£å¸¸
- [ ] æ€§èƒ½æŒ‡æ ‡æ­£å¸¸

### ç›‘æ§è®¾ç½®
- [ ] å¥åº·æ£€æŸ¥è„šæœ¬å·²è®¾ç½®
- [ ] è‡ªåŠ¨å¤‡ä»½å·²é…ç½®
- [ ] æ—¥å¿—è½®è½¬å·²é…ç½®
- [ ] ç£ç›˜ç©ºé—´ç›‘æ§å·²è®¾ç½®
- [ ] æœåŠ¡çŠ¶æ€ç›‘æ§å·²è®¾ç½®

---

ğŸ“ **éƒ¨ç½²æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
ğŸ•’ **æœ€åæ›´æ–°**: 2025-07-22  
ğŸš€ **ç”Ÿäº§ç¯å¢ƒ**: http://45.149.156.216:3001  
ğŸ“ **æŠ€æœ¯æ”¯æŒ**: [GitHub Issues](https://github.com/zylen97/research-dashboard/issues)